{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc007610-ef71-456c-a2eb-4dc3b74534f8",
   "metadata": {},
   "source": [
    "# S E N T I M E N T   A N A L Y S I S      O N          M O V I E   R E V I E W S\n",
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb47980-e588-4176-b815-ab7b84f170c7",
   "metadata": {},
   "source": [
    "## This script implements the full workflow for a sentiment analysis project,\n",
    "## now upgraded to use a real dataset and interactive user input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186da274-4d00-41ef-9dfe-3f7048074414",
   "metadata": {},
   "source": [
    "### ***--- Core Libraries ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15891b29-e15d-4ce8-952d-b7e0a1f08e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363758dd-b6f6-4da4-9f85-31999649f704",
   "metadata": {},
   "source": [
    "### Suppress warnings for cleaner output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185b84af-2377-4a8f-8aa2-b224002d107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07169813-f46b-4093-ad69-c37699061664",
   "metadata": {},
   "source": [
    "### ***--- 1. Data Loading & Preparation ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a7bad5-7dfd-4cd8-abeb-c06192c02a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Loading & Preparation ---\n",
      "IMDB Dataset loaded successfully.\n",
      "Using a sample of 10000 reviews for training.\n",
      "Dataset Head:\n",
      "                                                  review sentiment\n",
      "33553  I really liked this Summerslam due to the look...  positive\n",
      "9427   Not many television shows appeal to quite as m...  positive\n",
      "199    The film quickly gets to a major chase scene w...  negative\n",
      "12447  Jane Austen would definitely approve of this o...  positive\n",
      "39489  Expectations were somewhat high for me when I ...  negative\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Data Loading & Preparation ---\")\n",
    "try:\n",
    "    # Load the dataset. Make sure 'IMDB Dataset.csv' is in the same directory.\n",
    "    df = pd.read_csv('IMDB Dataset.csv')\n",
    "    print(\"IMDB Dataset loaded successfully.\")\n",
    "    # For performance, we'll work with a smaller sample of the data.\n",
    "    # Remove this line to train on the full 50k reviews (will take longer).\n",
    "    df = df.sample(n=10000, random_state=42)\n",
    "    print(f\"Using a sample of {len(df)} reviews for training.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'IMDB Dataset.csv' not found.\")\n",
    "    print(\"Please download the dataset and place it in the same directory as this script.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Dataset Head:\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3417d-aa13-46b5-b0d7-60041b859520",
   "metadata": {},
   "source": [
    "### ***--- 2. Data Cleaning (Preprocessing) ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d962adc-2b21-4679-bc40-8fbe1ea504b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Applying Preprocessing ---\n",
      "Preprocessing complete. 'cleaned_review' column added.\n",
      "                                          cleaned_review sentiment\n",
      "33553  i really liked this summerslam due to the look...  positive\n",
      "9427   not many television shows appeal to quite as m...  positive\n",
      "199    the film quickly gets to a major chase scene w...  negative\n",
      "12447  jane austen would definitely approve of this o...  positive\n",
      "39489  expectations were somewhat high for me when i ...  negative\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Applying Preprocessing ---\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses a single piece of text.\n",
    "    - Removes HTML tags\n",
    "    - Removes noise (punctuation, special characters)\n",
    "    - Normalizes text (converts to lowercase)\n",
    "    \"\"\"\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<br\\s*/?>', ' ', text) # Specifically handle <br> tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'review' column\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "print(\"Preprocessing complete. 'cleaned_review' column added.\")\n",
    "print(df[['cleaned_review', 'sentiment']].head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87345e11-41d1-432b-912b-b9b49cd702e4",
   "metadata": {},
   "source": [
    "### ***--- 3. Feature Extraction (TF-IDF) & Data Splitting ---***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "342cd72d-dbbb-401a-8a76-ebcf9c49944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Extraction & Data Splitting ---\n",
      "Fitting TF-IDF Vectorizer and transforming training data...\n",
      "Data split into 8000 training samples and 2000 testing samples.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Feature Extraction & Data Splitting ---\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df['cleaned_review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "# - `stop_words='english'`: Removes common English words.\n",
    "# - `max_features=5000`: Considers the top 5000 words to balance performance and accuracy.\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Fit the vectorizer on the training data and transform it\n",
    "print(\"Fitting TF-IDF Vectorizer and transforming training data...\")\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Only transform the test data using the already-fitted vectorizer\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "print(f\"Data split into {X_train_tfidf.shape[0]} training samples and {X_test_tfidf.shape[0]} testing samples.\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e829e-83e1-4347-8f75-ada0861de0e8",
   "metadata": {},
   "source": [
    "### ***--- 4. Model Training ---***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a471020c-9b5a-4b65-9db6-5558253101db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Training ---\n",
      "Training Logistic Regression model...\n",
      "Model training complete.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Model Training ---\")\n",
    "\n",
    "# We will use Logistic Regression as it's a strong and efficient baseline.\n",
    "print(\"Training Logistic Regression model...\")\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "print(\"Model training complete.\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92039269-7821-4214-a205-1a544f8487fc",
   "metadata": {},
   "source": [
    "### ***--- 5. Model Evaluation ---***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "506842f4-f686-4479-98c4-1d8694dbeb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Evaluation ---\n",
      "Evaluating model on the test set...\n",
      "Accuracy: 0.864\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       992\n",
      "    positive       0.85      0.89      0.87      1008\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.87      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Model Evaluation ---\")\n",
    "print(\"Evaluating model on the test set...\")\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567384b-0337-4dcf-b551-7f5304aeadae",
   "metadata": {},
   "source": [
    "### ***--- 6. Interactive Sentiment Analysis ---***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa5be80-d875-47b9-81b6-144c0c5fdec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Interactive Sentiment Analyzer ---\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the movie name you want to review:  Uggram\n",
      "Enter your review for 'Uggram':  Gangster look film\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "  A N A L Y S I S   R E S U L T\n",
      "--------------------\n",
      "Movie: Uggram\n",
      "Predicted Sentiment: POSITIVE\n",
      "Confidence: 58.58%\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to analyze another review? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Interactive Sentiment Analyzer ---\")\n",
    "\n",
    "def analyze_user_review():\n",
    "    \"\"\"\n",
    "    Takes user input for a movie and review, and predicts the sentiment.\n",
    "    \"\"\"\n",
    "    movie_name = input(\"Enter the movie name you want to review: \")\n",
    "    user_review = input(f\"Enter your review for '{movie_name}': \")\n",
    "\n",
    "    if not user_review.strip():\n",
    "        print(\"\\nReview is empty. Please enter some text.\")\n",
    "        return\n",
    "\n",
    "    # 1. Preprocess the user's review\n",
    "    cleaned_review = preprocess_text(user_review)\n",
    "\n",
    "    # 2. Vectorize the cleaned review using the same fitted vectorizer\n",
    "    review_tfidf = vectorizer.transform([cleaned_review])\n",
    "\n",
    "    # 3. Predict the sentiment using the trained model\n",
    "    prediction = model.predict(review_tfidf)\n",
    "    prediction_proba = model.predict_proba(review_tfidf)\n",
    "\n",
    "    # 4. Display the result\n",
    "    sentiment = prediction[0]\n",
    "    confidence = prediction_proba[0].max() * 100\n",
    "\n",
    "    print(\"\\n\" + \"-\"*20)\n",
    "    print(\"  A N A L Y S I S   R E S U L T\")\n",
    "    print(\"-\"*20)\n",
    "    print(f\"Movie: {movie_name}\")\n",
    "    print(f\"Predicted Sentiment: {sentiment.upper()}\")\n",
    "    print(f\"Confidence: {confidence:.2f}%\")\n",
    "    print(\"-\"*20)\n",
    "\n",
    "# Start the interactive loop\n",
    "while True:\n",
    "    analyze_user_review()\n",
    "    another = input(\"\\nDo you want to analyze another review? (yes/no): \").lower()\n",
    "    if another != 'yes':\n",
    "        print(\"Thank you for using the Sentiment Analyzer!\")\n",
    "        break\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6619cc2-b393-4386-a2b3-59655d04d2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
